{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "einsum (Einstein Summation) is a concise way to express tensor contractions, reductions, outer products, and attention ops using index notation."
      ],
      "metadata": {
        "id": "vMJO3YvVnIcv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dot Product"
      ],
      "metadata": {
        "id": "RJxJ9fp6mEfX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6mh6PlAl695",
        "outputId": "22d8a4b4-35d1-47b2-a2dc-f40f22a3becc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(32.)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "a = torch.tensor([1.0, 2.0, 3.0])\n",
        "b = torch.tensor([4.0, 5.0, 6.0])\n",
        "\n",
        "out = torch.einsum('i,i->', a, b)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outer Product"
      ],
      "metadata": {
        "id": "PNgXYOQXmwRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1., 2.])\n",
        "b = torch.tensor([4., 5., 6.])\n",
        "\n",
        "out = torch.einsum('i,j->ij', a, b)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y9QaIYVmvpW",
        "outputId": "6dcb142e-e88f-46fa-a81b-90397150cd5c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4.,  5.,  6.],\n",
            "        [ 8., 10., 12.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix Vector Multiplication"
      ],
      "metadata": {
        "id": "fJxelwi9nl9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.tensor([[1., 2., 3.], [4., 5., 6.]])  # (2, 3)\n",
        "x = torch.tensor([7., 8., 9.])                 # (3,)\n",
        "\n",
        "out = torch.einsum('ij,j->i', A, x)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV0XuQFsnubS",
        "outputId": "d5ce5c64-4780-4864-be72-aea5a4920171"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 50., 122.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix Matrix Multiplication"
      ],
      "metadata": {
        "id": "BdWUQxOCn4-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.randn(2, 3)\n",
        "B = torch.randn(3, 4)\n",
        "\n",
        "out = torch.einsum('ik,kj->ij', A, B)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLpsOEMGn9FM",
        "outputId": "100725a3-51e6-4c0f-f226-e5b7904ffa16"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0750,  0.5085,  0.8904, -2.2504],\n",
            "        [-0.2206,  0.1441,  1.8318, -0.2015]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batched Matrix Multiplication"
      ],
      "metadata": {
        "id": "Vage6tG8oMZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.randn(10, 2, 3)\n",
        "B = torch.randn(10, 3, 4)\n",
        "\n",
        "out = torch.einsum('bij,bjk->bik', A, B)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-00vK5utoPqG",
        "outputId": "9c11f5d5-b5c9-49f3-afa7-18873f80e1ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0195, -0.7816, -0.8763,  2.2061],\n",
            "         [ 0.5668,  1.1220, -1.2224,  0.1161]],\n",
            "\n",
            "        [[-0.3294, -0.1741,  0.4972,  3.6834],\n",
            "         [-0.7849, -2.6441, -1.6246,  1.5197]],\n",
            "\n",
            "        [[ 1.3685,  1.8194, -0.4677,  1.3664],\n",
            "         [-0.9079,  1.1539, -2.0940, -1.2011]],\n",
            "\n",
            "        [[-2.2159, -0.4520,  0.2183,  0.0462],\n",
            "         [ 1.6361,  0.1408, -1.5980,  0.5484]],\n",
            "\n",
            "        [[ 0.4013,  0.6323,  1.6513, -2.1926],\n",
            "         [ 2.7024,  0.3602,  0.8489, -2.5955]],\n",
            "\n",
            "        [[ 0.7844, -0.6573,  2.4862,  2.8324],\n",
            "         [ 0.2876,  0.4176, -1.8220, -2.4041]],\n",
            "\n",
            "        [[-1.1543,  1.0726, -1.5795,  1.2047],\n",
            "         [-1.0551,  1.3986,  0.6860,  0.9939]],\n",
            "\n",
            "        [[ 2.4141, -2.3396, -0.7182, -1.0035],\n",
            "         [ 0.6322,  0.8609,  0.8573, -0.2625]],\n",
            "\n",
            "        [[ 0.9789,  1.9025,  0.1274, -2.3324],\n",
            "         [ 1.0936,  0.4009, -0.1842, -0.9831]],\n",
            "\n",
            "        [[ 0.2554,  0.1552, -2.9759,  0.2129],\n",
            "         [ 3.7971,  0.1569, -2.4792,  2.4251]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax Attention Scores\n",
        "\n",
        "\n",
        "Computes Q Ã— Káµ€ per head\n",
        "\n",
        "Each score: dot product between query & key."
      ],
      "metadata": {
        "id": "Igapgm1epXwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q = torch.randn(64, 8, 20, 64)  # (batch, heads, queries, dim)\n",
        "K = torch.randn(64, 8, 64, 64)  # (batch, heads, keys, dim)\n",
        "\n",
        "scores = torch.einsum('bhqd,bhkd->bhqk', Q, K)\n",
        "print(scores.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oibsWr1LoPXg",
        "outputId": "69e05c26-0555-4463-cd2c-b5dfd506f390"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 8, 20, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Context Vector via Attention"
      ],
      "metadata": {
        "id": "oKLbVrBBp5nW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attn = torch.randn(64, 8, 20, 64) # attention weights\n",
        "V = torch.randn(64, 8, 64, 64) # values\n",
        "context = torch.einsum('bhqk,bhkd->bhqd', attn, V) # weighed sum of values using attention scores\n",
        "\n",
        "print(context.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzbo8nzJp9sn",
        "outputId": "806c31e0-c5d0-47c2-88c8-863ebf388296"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 8, 20, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is the operation:\n",
        "\n",
        "ðŸ”² A simple dot/matmul/batch matmul?\n",
        "    â†’ Use matmul / bmm\n",
        "\n",
        "ðŸ”² Complex contraction, like multi-axis or attention?\n",
        "    â†’ Use einsum\n",
        "\n",
        "ðŸ”² You care about speed or memory?\n",
        "    â†’ Profile first. Rewrite einsum to bmm/matmul if needed.\n"
      ],
      "metadata": {
        "id": "ifrhgS-uq8rO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Profiling *einsum*"
      ],
      "metadata": {
        "id": "b3Wm0hjsrAKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "a = torch.randn(512, 512).cuda()\n",
        "b = torch.randn(512, 512).cuda()\n",
        "\n",
        "with profile(activities = [ProfilerActivity.CPU, ProfilerActivity.CUDA]) as profiling:\n",
        "  with record_function(\"einsum\"):\n",
        "    torch.einsum('ik,kj->ij', a, b)\n",
        "\n",
        "print(profiling.key_averages().table(sort_by = \"cuda_time_total\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avxHqcuBrQLP",
        "outputId": "4d01ca3e-c418-4916-c2cd-15d3625ab707"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           einsum         7.29%      11.855ms        99.99%     162.586ms     162.586ms       0.000us         0.00%     788.904us     788.904us             1  \n",
            "                                     aten::einsum         8.71%      14.154ms        92.70%     150.731ms     150.731ms       0.000us         0.00%     788.904us     788.904us             1  \n",
            "                                        aten::bmm        46.41%      75.460ms        80.99%     131.689ms     131.689ms     131.484us       100.00%     788.904us     788.904us             1  \n",
            "                                     Unrecognized         5.34%       8.676ms         5.34%       8.676ms       1.735ms     657.420us       500.00%     657.420us     131.484us             5  \n",
            "    cudaOccupancyMaxActiveBlocksPerMultiprocessor         0.02%      24.861us         5.14%       8.362ms       4.181ms       0.000us         0.00%     394.452us     197.226us             2  \n",
            "                             cudaGetSymbolAddress        24.17%      39.306ms        24.38%      39.645ms      39.645ms       0.000us         0.00%     262.968us     262.968us             1  \n",
            "                            volta_sgemm_128x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us     131.484us       100.00%     131.484us     131.484us             1  \n",
            "                                           einsum         0.00%       0.000us         0.00%       0.000us       0.000us     131.484us       100.00%     131.484us     131.484us             1  \n",
            "                                  aten::unsqueeze         0.28%     458.916us         1.82%       2.953ms       1.477ms       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                 aten::as_strided         1.54%       2.505ms         1.54%       2.505ms     357.847us       0.000us         0.00%       0.000us       0.000us             7  \n",
            "                                    aten::permute         1.15%       1.873ms         1.16%       1.884ms     376.806us       0.000us         0.00%       0.000us       0.000us             5  \n",
            "                                    aten::reshape         0.01%      15.875us         0.02%      32.790us      16.395us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                       aten::view         0.02%      34.418us         0.02%      34.418us       8.605us       0.000us         0.00%       0.000us       0.000us             4  \n",
            "                            cudaStreamIsCapturing         0.01%       8.882us         0.01%       8.882us       4.441us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                       cudaMalloc         1.56%       2.531ms         1.56%       2.531ms     506.284us       0.000us         0.00%       0.000us       0.000us             5  \n",
            "                                         cudaFree         3.02%       4.908ms         3.02%       4.908ms       4.908ms       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                           cudaDeviceGetAttribute         0.00%       6.222us         0.00%       6.222us       0.346us       0.000us         0.00%       0.000us       0.000us            18  \n",
            "                          cudaGetDriverEntryPoint         0.00%       1.617us         0.00%       1.617us       0.809us       0.000us         0.00%       0.000us       0.000us             2  \n",
            "                                 cudaLaunchKernel         0.47%     765.884us         0.47%     765.884us     765.884us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                            cudaDeviceSynchronize         0.01%      12.285us         0.01%      12.285us      12.285us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 162.598ms\n",
            "Self CUDA time total: 131.484us\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Profiling *bmm* and *matmul*"
      ],
      "metadata": {
        "id": "wIingyhZsRsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "B, M, K, N = 128, 64, 64, 64\n",
        "A = torch.randn(B, M, K, device='cuda')\n",
        "B_ = torch.randn(B, K, N, device='cuda')\n",
        "\n",
        "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    with record_function(\"einsum\"):\n",
        "        torch.einsum('bik,bkj->bij', A, B_)\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    with record_function(\"bmm\"):\n",
        "        torch.bmm(A, B_)\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    with record_function(\"matmul\"):\n",
        "        torch.matmul(A, B_)\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgLgdkHjsRVI",
        "outputId": "e4e0425c-0d81-4838-e7e4-822fe6c80d7b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                aten::bmm        12.75%     158.883us        65.15%     811.618us     270.539us     145.338us       100.00%     145.338us      48.446us             3  \n",
            "     volta_sgemm_64x64_nn         0.00%       0.000us         0.00%       0.000us       0.000us     145.338us       100.00%     145.338us      48.446us             3  \n",
            "                      bmm         4.58%      57.023us         9.47%     118.011us     118.011us       0.000us         0.00%      48.734us      48.734us             1  \n",
            "                      bmm         0.00%       0.000us         0.00%       0.000us       0.000us      48.734us        33.53%      48.734us      48.734us             1  \n",
            "                   matmul         2.86%      35.588us         9.40%     117.086us     117.086us       0.000us         0.00%      48.318us      48.318us             1  \n",
            "             aten::matmul         1.36%      16.975us         6.54%      81.498us      81.498us       0.000us         0.00%      48.318us      48.318us             1  \n",
            "                   matmul         0.00%       0.000us         0.00%       0.000us       0.000us      48.318us        33.25%      48.318us      48.318us             1  \n",
            "                   einsum        12.14%     151.209us        77.71%     968.125us     968.125us       0.000us         0.00%      48.286us      48.286us             1  \n",
            "             aten::einsum         3.90%      48.614us        65.57%     816.916us     816.916us       0.000us         0.00%      48.286us      48.286us             1  \n",
            "                   einsum         0.00%       0.000us         0.00%       0.000us       0.000us      48.286us        33.22%      48.286us      48.286us             1  \n",
            "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 1.246ms\n",
            "Self CUDA time total: 145.338us\n",
            "\n"
          ]
        }
      ]
    }
  ]
}